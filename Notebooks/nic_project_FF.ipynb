{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "WCuShOkezNAd"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models, Model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import kagglehub\n",
        "import math\n",
        "import time\n",
        "import gc"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "os.environ['PYTHONHASHSEED'] = str(SEED)"
      ],
      "metadata": {
        "id": "tuRsPo-OzOy4"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Downloading dataset...\")\n",
        "path = kagglehub.dataset_download(\"bhaveshmittal/melanoma-cancer-dataset\")\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mAuip2SazRbU",
        "outputId": "ede684ce-7e01-4085-b36c-7fce650856e9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading dataset...\n",
            "Using Colab cache for faster access to the 'melanoma-cancer-dataset' dataset.\n",
            "Path to dataset files: /kaggle/input/melanoma-cancer-dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGE_WIDTH = 64\n",
        "IMAGE_HEIGHT = 64\n",
        "BATCH_SIZE = 32\n",
        "INPUT_SHAPE = (IMAGE_WIDTH, IMAGE_HEIGHT, 3)"
      ],
      "metadata": {
        "id": "vL7cLurgzS0C"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1.0 / 255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    validation_split=0.4\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(\n",
        "    rescale=1.0 / 255,\n",
        "    validation_split=0.4\n",
        ")\n",
        "\n",
        "# Load Data\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    path + '/train',\n",
        "    target_size=(IMAGE_WIDTH, IMAGE_HEIGHT),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',\n",
        "    subset='training',\n",
        "    seed=SEED\n",
        ")\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    path + '/train',\n",
        "    target_size=(IMAGE_WIDTH, IMAGE_HEIGHT),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',\n",
        "    subset='validation',\n",
        "    seed=SEED\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UMLB53F-zUec",
        "outputId": "233d537e-af03-4596-940b-86a5967324b7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 7128 images belonging to 2 classes.\n",
            "Found 4751 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(\n",
        "    filters1, filters2, dropout1, dropout2,\n",
        "    learning_rate, activation, last_activation,\n",
        "    keep_model=False\n",
        "):\n",
        "    model = models.Sequential([\n",
        "        layers.Conv2D(filters=filters1, kernel_size=(3, 3), activation=activation,\n",
        "                      input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, 3)),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "        layers.Conv2D(filters=filters2, kernel_size=(3, 3), activation=activation),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "        layers.Conv2D(filters=128, kernel_size=(3, 3), activation=activation),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(units=128, activation=activation),\n",
        "        layers.Dropout(dropout1),\n",
        "        layers.Dense(units=64, activation=activation),\n",
        "        layers.Dropout(dropout2),\n",
        "        layers.Dense(units=1, activation=last_activation)\n",
        "    ])\n",
        "\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss=\"binary_crossentropy\",\n",
        "        metrics=[\"accuracy\"]\n",
        "    )\n",
        "\n",
        "    history = model.fit(\n",
        "        train_generator,\n",
        "        steps_per_epoch=train_generator.samples // BATCH_SIZE,\n",
        "        epochs=4,\n",
        "        validation_data=validation_generator,\n",
        "        validation_steps=validation_generator.samples // BATCH_SIZE,\n",
        "        verbose=0\n",
        "    )\n",
        "\n",
        "    val_acc = history.history[\"val_accuracy\"][-1]\n",
        "\n",
        "    # ===== MEMORY SAFE CLEANUP =====\n",
        "    if not keep_model:\n",
        "        tf.keras.backend.clear_session()\n",
        "        del model\n",
        "        del history\n",
        "        del optimizer\n",
        "        return val_acc, None, None\n",
        "    # ===============================\n",
        "\n",
        "    return val_acc, model, history"
      ],
      "metadata": {
        "id": "_CtmB5MpzW3q"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "search_space = {}\n",
        "search_space['filters1'] = [32, 64, 128]\n",
        "search_space['filters2'] = [32,64,128]\n",
        "search_space['dropout1'] = [0.1, 0.3, 0.5, 0.7]\n",
        "search_space['dropout2'] = [0.1, 0.3, 0.5, 0.7]\n",
        "search_space['learning_rate'] = [0.0001, 0.001, 0.01, 0.1]\n",
        "search_space['activation'] = ['relu', 'elu', 'gelu']\n",
        "search_space['last_activation'] = ['sigmoid']"
      ],
      "metadata": {
        "id": "lLuXswT_1LLy"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def firefly_search(n=5, max_iter=5, alpha=0.2, beta0=1, gamma=1):\n",
        "    print(f\"  -> Firefly Start (n={n}, Iter={max_iter}, alpha={alpha}, beta0={beta0}, gamma={gamma})\")\n",
        "\n",
        "    # ----- Bounds derived from search space -----\n",
        "    lb = np.array([\n",
        "        min(search_space['filters1']),\n",
        "        min(search_space['filters2']),\n",
        "        min(search_space['dropout1']),\n",
        "        min(search_space['dropout2']),\n",
        "        min(search_space['learning_rate'])\n",
        "    ])\n",
        "\n",
        "    ub = np.array([\n",
        "        max(search_space['filters1']),\n",
        "        max(search_space['filters2']),\n",
        "        max(search_space['dropout1']),\n",
        "        max(search_space['dropout2']),\n",
        "        max(search_space['learning_rate'])\n",
        "    ])\n",
        "\n",
        "    # ----- Initialize fireflies (continuous) -----\n",
        "    fireflies = np.zeros((n, 5))\n",
        "    for d in range(5):\n",
        "        fireflies[:, d] = np.random.uniform(lb[d], ub[d], n)\n",
        "\n",
        "    fitness = np.zeros(n)\n",
        "\n",
        "    # ----- Initial Evaluation -----\n",
        "    for k in range(n):\n",
        "        state = (\n",
        "            int(round(fireflies[k, 0])),     # filters1\n",
        "            int(round(fireflies[k, 1])),     # filters2\n",
        "            fireflies[k, 2],                  # dropout1\n",
        "            fireflies[k, 3],                  # dropout2\n",
        "            fireflies[k, 4],                  # learning_rate\n",
        "            'relu',                           # activation (FIXED)\n",
        "            'sigmoid'                         # last_activation (FIXED)\n",
        "        )\n",
        "\n",
        "        print(\n",
        "            f\"    Evaluating Initial Firefly {k+1}/{n}: \"\n",
        "            f\"F1={state[0]}, F2={state[1]}, \"\n",
        "            f\"D1={state[2]:.2f}, D2={state[3]:.2f}, LR={state[4]:.5f}\"\n",
        "        )\n",
        "\n",
        "        acc, _, _ = evaluate_model(*state, keep_model=False)\n",
        "        fitness[k] = acc\n",
        "\n",
        "        print(f\"      -> Accuracy: {acc:.4f}\")\n",
        "\n",
        "        tf.keras.backend.clear_session()\n",
        "        gc.collect()\n",
        "\n",
        "    # ----- Main Loop -----\n",
        "    for t in range(max_iter):\n",
        "        print(f\"\\n--- Iteration {t+1}/{max_iter} ---\")\n",
        "\n",
        "        for i in range(n):\n",
        "            for j in range(n):\n",
        "                if fitness[j] > fitness[i]:\n",
        "                    r = np.linalg.norm(fireflies[i] - fireflies[j])\n",
        "                    beta = beta0 * np.exp(-gamma * r**2)\n",
        "                    zeta = np.random.normal(0, 1, size=5)\n",
        "\n",
        "                    fireflies[i] += beta * (fireflies[j] - fireflies[i]) + alpha * zeta\n",
        "                    fireflies[i] = np.clip(fireflies[i], lb, ub)\n",
        "\n",
        "                    state = (\n",
        "                        int(round(fireflies[i, 0])),\n",
        "                        int(round(fireflies[i, 1])),\n",
        "                        fireflies[i, 2],\n",
        "                        fireflies[i, 3],\n",
        "                        fireflies[i, 4],\n",
        "                        'relu',\n",
        "                        'sigmoid'\n",
        "                    )\n",
        "\n",
        "                    print(\n",
        "                        f\"    Firefly {i} moved towards {j}. \"\n",
        "                        f\"Evaluating new position...\"\n",
        "                    )\n",
        "\n",
        "                    acc, _, _ = evaluate_model(*state, keep_model=False)\n",
        "                    fitness[i] = acc\n",
        "\n",
        "                    print(f\"      -> New Accuracy: {acc:.4f}\")\n",
        "\n",
        "                    tf.keras.backend.clear_session()\n",
        "                    gc.collect()\n",
        "\n",
        "    best_index = int(np.argmax(fitness))\n",
        "\n",
        "    best_state = (\n",
        "        int(round(fireflies[best_index, 0])),\n",
        "        int(round(fireflies[best_index, 1])),\n",
        "        fireflies[best_index, 2],\n",
        "        fireflies[best_index, 3],\n",
        "        fireflies[best_index, 4],\n",
        "        'relu',\n",
        "        'sigmoid'\n",
        "    )\n",
        "\n",
        "    print(f\"\\n  -> Firefly Finished. Best Accuracy: {fitness[best_index]:.4f}\")\n",
        "\n",
        "    return best_state, fitness[best_index]"
      ],
      "metadata": {
        "id": "1iXq3wOkzY6P"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "best_state, best_acc = firefly_search(n=3, max_iter=10, alpha=0.2, beta0=1, gamma=1)\n",
        "end_time = time.time()\n",
        "print(f\"Time taken: {end_time - start_time:.2f} seconds\")\n",
        "print(f\"Best State: {best_state}\")\n",
        "print(f\"Best Accuracy: {best_acc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OUbWDhuwzya_",
        "outputId": "304f1ebc-bdce-461e-96a7-c3aa059fd651"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  -> Firefly Start (n=3, Iter=10, alpha=0.2, beta0=1, gamma=1)\n",
            "    Evaluating Initial Firefly 1/3: F1=68, F2=89, D1=0.13, D2=0.52, LR=0.08326\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/epoch_iterator.py:116: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      -> Accuracy: 0.5285\n",
            "    Evaluating Initial Firefly 2/3: F1=123, F2=47, D1=0.62, D2=0.11, LR=0.02131\n",
            "      -> Accuracy: 0.5293\n",
            "    Evaluating Initial Firefly 3/3: F1=102, F2=47, D1=0.46, D2=0.68, LR=0.01826\n",
            "      -> Accuracy: 0.5293\n",
            "\n",
            "--- Iteration 1/10 ---\n",
            "    Firefly 0 moved towards 1. Evaluating new position...\n",
            "      -> New Accuracy: 0.7975\n",
            "    Firefly 1 moved towards 0. Evaluating new position...\n",
            "      -> New Accuracy: 0.5293\n",
            "    Firefly 2 moved towards 0. Evaluating new position...\n",
            "      -> New Accuracy: 0.7918\n",
            "\n",
            "--- Iteration 2/10 ---\n",
            "    Firefly 1 moved towards 0. Evaluating new position...\n",
            "      -> New Accuracy: 0.5287\n",
            "    Firefly 1 moved towards 2. Evaluating new position...\n",
            "      -> New Accuracy: 0.5289\n",
            "    Firefly 2 moved towards 0. Evaluating new position...\n",
            "      -> New Accuracy: 0.7848\n",
            "\n",
            "--- Iteration 3/10 ---\n",
            "    Firefly 1 moved towards 0. Evaluating new position...\n",
            "      -> New Accuracy: 0.5296\n",
            "    Firefly 1 moved towards 2. Evaluating new position...\n",
            "      -> New Accuracy: 0.5293\n",
            "    Firefly 2 moved towards 0. Evaluating new position...\n",
            "      -> New Accuracy: 0.7943\n",
            "\n",
            "--- Iteration 4/10 ---\n",
            "    Firefly 1 moved towards 0. Evaluating new position...\n",
            "      -> New Accuracy: 0.5293\n",
            "    Firefly 1 moved towards 2. Evaluating new position...\n",
            "      -> New Accuracy: 0.8000\n",
            "    Firefly 2 moved towards 0. Evaluating new position...\n",
            "      -> New Accuracy: 0.7941\n",
            "    Firefly 2 moved towards 1. Evaluating new position...\n",
            "      -> New Accuracy: 0.5296\n",
            "\n",
            "--- Iteration 5/10 ---\n",
            "    Firefly 0 moved towards 1. Evaluating new position...\n",
            "      -> New Accuracy: 0.8009\n",
            "    Firefly 1 moved towards 0. Evaluating new position...\n",
            "      -> New Accuracy: 0.5291\n",
            "    Firefly 1 moved towards 2. Evaluating new position...\n",
            "      -> New Accuracy: 0.5289\n",
            "    Firefly 2 moved towards 0. Evaluating new position...\n",
            "      -> New Accuracy: 0.5291\n",
            "\n",
            "--- Iteration 6/10 ---\n",
            "    Firefly 1 moved towards 0. Evaluating new position...\n",
            "      -> New Accuracy: 0.5291\n",
            "    Firefly 2 moved towards 0. Evaluating new position...\n",
            "      -> New Accuracy: 0.4702\n",
            "    Firefly 2 moved towards 1. Evaluating new position...\n",
            "      -> New Accuracy: 0.7943\n",
            "\n",
            "--- Iteration 7/10 ---\n",
            "    Firefly 1 moved towards 0. Evaluating new position...\n",
            "      -> New Accuracy: 0.5289\n",
            "    Firefly 1 moved towards 2. Evaluating new position...\n",
            "      -> New Accuracy: 0.5293\n",
            "    Firefly 2 moved towards 0. Evaluating new position...\n",
            "      -> New Accuracy: 0.4711\n",
            "    Firefly 2 moved towards 1. Evaluating new position...\n",
            "      -> New Accuracy: 0.4709\n",
            "\n",
            "--- Iteration 8/10 ---\n",
            "    Firefly 1 moved towards 0. Evaluating new position...\n",
            "      -> New Accuracy: 0.4709\n",
            "    Firefly 2 moved towards 0. Evaluating new position...\n",
            "      -> New Accuracy: 0.7880\n",
            "\n",
            "--- Iteration 9/10 ---\n",
            "    Firefly 1 moved towards 0. Evaluating new position...\n",
            "      -> New Accuracy: 0.5296\n",
            "    Firefly 1 moved towards 2. Evaluating new position...\n",
            "      -> New Accuracy: 0.5291\n",
            "    Firefly 2 moved towards 0. Evaluating new position...\n",
            "      -> New Accuracy: 0.7333\n",
            "\n",
            "--- Iteration 10/10 ---\n",
            "    Firefly 1 moved towards 0. Evaluating new position...\n",
            "      -> New Accuracy: 0.5298\n",
            "    Firefly 1 moved towards 2. Evaluating new position...\n",
            "      -> New Accuracy: 0.5296\n",
            "    Firefly 2 moved towards 0. Evaluating new position...\n",
            "      -> New Accuracy: 0.4704\n",
            "    Firefly 2 moved towards 1. Evaluating new position...\n",
            "      -> New Accuracy: 0.7798\n",
            "\n",
            "  -> Firefly Finished. Best Accuracy: 0.8009\n",
            "Time taken: 3328.89 seconds\n",
            "Best State: (68, 90, np.float64(0.1), np.float64(0.47720319464863553), np.float64(0.0001), 'relu', 'sigmoid')\n",
            "Best Accuracy: 0.8009\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_generator = test_datagen.flow_from_directory(\n",
        "    path + '/test',\n",
        "    target_size=(IMAGE_WIDTH, IMAGE_HEIGHT),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',\n",
        "    subset='training',\n",
        "    shuffle=False,\n",
        "    seed=SEED\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NXhwSZBw0mcT",
        "outputId": "a710b084-9ea4-4dd3-9a99-b160f36747f1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1200 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filters1, filters2, dropout1, dropout2, learning_rate, activation, last_activation = best_state\n",
        "\n",
        "optimized_model = models.Sequential([\n",
        "    layers.Conv2D(filters=filters1, kernel_size=(3, 3), activation=activation, input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, 3)),\n",
        "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "    layers.Conv2D(filters=filters2, kernel_size=(3, 3), activation=activation),\n",
        "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "    layers.Conv2D(filters=128, kernel_size=(3, 3), activation=activation),\n",
        "    layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(units=128, activation=activation),\n",
        "    layers.Dropout(dropout1),\n",
        "    layers.Dense(units=64, activation=activation),\n",
        "    layers.Dropout(dropout2),\n",
        "    layers.Dense(units=1, activation=last_activation)\n",
        "])\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "optimized_model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=1e-6)\n",
        "\n",
        "history = optimized_model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // BATCH_SIZE,\n",
        "    epochs=20,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_generator.samples // BATCH_SIZE,\n",
        "    callbacks=[early_stopping, reduce_lr]\n",
        ")\n",
        "\n",
        "test_loss, test_acc = optimized_model.evaluate(test_generator)\n",
        "print(f\"Test accuracy: {test_acc}\")\n",
        "\n",
        "optimized_model.save('FF_optimized_melanoma_model.keras')\n",
        "print(\"Final model saved as FF_optimized_melanoma_model.keras\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_VPYVNCz4v5",
        "outputId": "5c5a0aa0-6863-484e-fe75-42370d3f88d2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 144ms/step - accuracy: 0.6663 - loss: 0.5978 - val_accuracy: 0.7367 - val_loss: 0.5218 - learning_rate: 1.0000e-04\n",
            "Epoch 2/20\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 53ms/step - accuracy: 0.8125 - loss: 0.4243 - val_accuracy: 0.7614 - val_loss: 0.4789 - learning_rate: 1.0000e-04\n",
            "Epoch 3/20\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 141ms/step - accuracy: 0.8078 - loss: 0.4209 - val_accuracy: 0.8190 - val_loss: 0.4080 - learning_rate: 1.0000e-04\n",
            "Epoch 4/20\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 54ms/step - accuracy: 0.7812 - loss: 0.4206 - val_accuracy: 0.8167 - val_loss: 0.4051 - learning_rate: 1.0000e-04\n",
            "Epoch 5/20\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 140ms/step - accuracy: 0.8346 - loss: 0.3757 - val_accuracy: 0.7796 - val_loss: 0.4398 - learning_rate: 1.0000e-04\n",
            "Epoch 6/20\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 54ms/step - accuracy: 0.8750 - loss: 0.2674 - val_accuracy: 0.7688 - val_loss: 0.4574 - learning_rate: 1.0000e-04\n",
            "Epoch 7/20\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 137ms/step - accuracy: 0.8398 - loss: 0.3658 - val_accuracy: 0.8271 - val_loss: 0.3880 - learning_rate: 1.0000e-04\n",
            "Epoch 8/20\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 54ms/step - accuracy: 0.8125 - loss: 0.3828 - val_accuracy: 0.8262 - val_loss: 0.3904 - learning_rate: 1.0000e-04\n",
            "Epoch 9/20\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 142ms/step - accuracy: 0.8497 - loss: 0.3381 - val_accuracy: 0.8224 - val_loss: 0.3933 - learning_rate: 1.0000e-04\n",
            "Epoch 10/20\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 54ms/step - accuracy: 0.7500 - loss: 0.5896 - val_accuracy: 0.8256 - val_loss: 0.3839 - learning_rate: 1.0000e-04\n",
            "Epoch 11/20\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 154ms/step - accuracy: 0.8495 - loss: 0.3340 - val_accuracy: 0.7610 - val_loss: 0.4921 - learning_rate: 1.0000e-04\n",
            "Epoch 12/20\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 60ms/step - accuracy: 0.7188 - loss: 0.4430 - val_accuracy: 0.7810 - val_loss: 0.4427 - learning_rate: 1.0000e-04\n",
            "Epoch 13/20\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 147ms/step - accuracy: 0.8590 - loss: 0.3306 - val_accuracy: 0.8326 - val_loss: 0.3771 - learning_rate: 1.0000e-04\n",
            "Epoch 14/20\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 55ms/step - accuracy: 0.9062 - loss: 0.3213 - val_accuracy: 0.8326 - val_loss: 0.3706 - learning_rate: 1.0000e-04\n",
            "Epoch 15/20\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 141ms/step - accuracy: 0.8615 - loss: 0.3253 - val_accuracy: 0.8372 - val_loss: 0.3659 - learning_rate: 1.0000e-04\n",
            "Epoch 16/20\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 52ms/step - accuracy: 0.7812 - loss: 0.3822 - val_accuracy: 0.8391 - val_loss: 0.3694 - learning_rate: 1.0000e-04\n",
            "Epoch 17/20\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 141ms/step - accuracy: 0.8675 - loss: 0.3086 - val_accuracy: 0.8442 - val_loss: 0.3609 - learning_rate: 1.0000e-04\n",
            "Epoch 18/20\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 55ms/step - accuracy: 0.8750 - loss: 0.2850 - val_accuracy: 0.8454 - val_loss: 0.3599 - learning_rate: 1.0000e-04\n",
            "Epoch 19/20\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 140ms/step - accuracy: 0.8573 - loss: 0.3278 - val_accuracy: 0.8298 - val_loss: 0.3772 - learning_rate: 1.0000e-04\n",
            "Epoch 20/20\n",
            "\u001b[1m222/222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 55ms/step - accuracy: 0.9062 - loss: 0.2962 - val_accuracy: 0.8269 - val_loss: 0.3792 - learning_rate: 1.0000e-04\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 157ms/step - accuracy: 0.8895 - loss: 0.2722\n",
            "Test accuracy: 0.8383333086967468\n",
            "Final model saved as FF_optimized_melanoma_model.keras\n"
          ]
        }
      ]
    }
  ]
}